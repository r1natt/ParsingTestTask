Тестовое задание на пасринг страницы

## Задание

### Задача:
Разработать Python-скрипт, который через HTTP-запросы авторизуется в интерфейсе phpMyAdmin и извлекает содержимое таблицы users из базы данных testDB.
### Условия окружения:
phpMyAdmin доступен по адресу http://185.xxx.xxx.162/phpmyadmin.

Для подключения используется логин ... и пароль ... 
В базе данных testDB имеется таблица users с тестовыми данными.

Требования к скрипту:
1. Скрипт должен быть написан на Python 3.x с использованием стандартных библиотек и/или requests, BeautifulSoup.
2. Выполнить авторизацию в phpMyAdmin по указанным учётным данным.
3. Перейти в базу данных testDB и извлечь содержимое таблицы users.
4. Вывести полученные данные в консоль в читаемом виде.
### Ограничения:
- Запрещено использовать Selenium, Playwright или иные инструменты управления браузером.
- Нельзя подключаться напрямую к MySQL (например, через pymysql, sqlalchemy и т.п.).
- Все действия должны выполняться через HTTP-запросы, эмулируя действия пользователя в веб-интерфейсе phpMyAdmin.
- Разрешается использовать DevTools (F12 в браузере), или иные средства (Fiddler, BurpSuite) для анализа запросов, которые выполняет интерфейс.

## Описание решения
**Ход решения:**
1. GET запрос страницы логина для получения токена и phpMyAdmin формы для дальнейшей отправки данных логина с этими токенами
2. POST запрос с отправкой данных авторизации (логин/пароль), ожидание pmaUser-1 и pmaAuth-1 в куках ответа (если они есть, значит логин успешен)
3. Ajax Запрос таблицы, которую и нужно спарсить
4. Парсинг таблицы с BS4, поиск хедеров и данных таблицы в ответе ajax запроса. По итогу получаются 2 списка:
	- список хедеров
	- список строк данных (каждая строка тоже список)
5. Вывод красивой таблицы с помощью PrettyTable

**Особенности**
- Для запросов используется requests.Session(), который сохраняет все куки запросов на протяжении всей сессии.
- Данные для входа выделены в отдельный конфиг файл
- Этапы работы программы логгируются

**Что можно дополнить(?)**
- Выделить логики в отдельные классы, чтобы парсер состоял из взаимозаменяемых функций парсинга страницы и классов запросов.
* Добавить try/except на возможные ошибки (Но тестовое маленькое, а сайт очевидно будет работать, поэтому я не стал этого делать)
